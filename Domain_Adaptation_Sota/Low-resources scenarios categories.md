[[2021 Hedderic - A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios]] defines also a categorization  for low-resource settings: 

	- Avaliability of the task-specific labels in the target language (or target domain) is the most prominent dimension in the context of supervised learning. Labels are usually created through manual annotation, which can be both time- and costintensive. Not having access to adequate experts to perform the annotation can also be an issue for some languages and domains
	- The availability of unlabeled language- or domain-specific text is another factor, especially as most modern NLP approaches are based on some form of input embeddings trained on unlabeled texts.
	- Most of the ideas surveyed in the next sections assume the availability of auxiliary data which can have many forms. Transfer learning might leverage task-specific labels in a different language or domain. Distant supervision utilizes external sources of information, such as knowledge bases or gazetteers. Some approaches require other NLP tools in the target language like machine translation to generate training data. It is essential to consider this as results from one low-resource scenario might not be transferable to another one if the assumptions on the auxiliary data are broken.