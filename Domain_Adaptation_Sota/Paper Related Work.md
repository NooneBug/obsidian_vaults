In this paper we define, experiment and analyse two scenarios of Domain Adaptation Tasks in Entity Typing. In this paragraph we underline state-of-the art notions in the domain adaptation research field that are related to our work.

As reported in [[2016 Plank - What to do about non-standard (or non-canonical) language in NLP]] in NLP there is no common ground on what constitutes a domain. From [[2018 Ramponi - Neural Unsupervised Domain Adaptation in NLP, A Survey]] three definitions for what a domain is [[What is a domain? Domain definitions]] can be extracted: Canonical vs Non-canonical, Dataset-Domain and Variety Space [[2016 Plank - What to do about non-standard (or non-canonical) language in NLP]]. The \textbf{Canonical vs Non-canonical} definition 
partitions all possible domains in two categories: a \textit{canonical domain} is typically defined by a well-edited (English) newswire corpus, a Non-canonical domain is tipycally defined by a corpus which comes from social media and or is non-well edited. This definition is highly contrasted by [[2016 Plank - What to do about non-standard (or non-canonical) language in NLP]] that reports different studies which underline how different communities can be seen as different domains indipendently if their documents comes from Canonical or Non-Canonical source, and so the classical domain notion in uneffective.  \textbf{Dataset-Domain} is not explicit pointed as a definition, it is a suggestion proposed in [[2018 Ramponi - Neural Unsupervised Domain Adaptation in NLP, A Survey]]; since Canonical vs Non-Canonical is uneffective, the authors ask themselves if each dataset defines its own domain, since each dataset has its sources and its document collection approaches. The authors leave this suggestion as a question, but they point as Variety Space as possible answer. [[Domain definition - Variety Space]] The Variety Space is a theoretical notion introduced by [[2016 Plank - What to do about non-standard (or non-canonical) language in NLP]]. Citing from  [[2016 Plank - What to do about non-standard (or non-canonical) language in NLP]] : "In the variety space a corpus is seen as a subspace (subregion), a sample of the variety space. A corpus is a set of instances drawn from the underlying unknown high-dimensional variety space, whose dimensions (or latent factors) are fuzzy language and annotation aspects. These latent factors can be related to the notions discussed above, such as genre (e.g., scientific, newswire, informal), sub-domain (e.g., finance, immunology, politics, environmental law, molecular biology) and socio-demographic aspects (e.g., gender), among other unknown factors, as well as stylistic or data sampling impacts (e.g., sentence length, annotator bias)". Like [[2018 Ramponi - Neural Unsupervised Domain Adaptation in NLP, A Survey]] we use variety space to answer to the Dataset-Domain question: since each dataset can be seen as a sample of the variety space, each dataset defines its own domain, but this sample is not exclusive and different datasets can share some regions of the variety space. In this paper we agree with the Dataset-Domain definition under the Variety Space: we assume that the four datasets used in the experiments share some regions in the variety space, but each one is also composed of exclusive regions of the variety space.  

Knowing the definition of domain, we now analyse how domain adaptation is defined and why is needed: Domain Adaptation is an instance of a particular case of Transfer Learning [[2009 Pan - A Survey on Transfer Learning]] called [[Transductive Transfer Learning]]. In Transductive Trasfer Learning the surce and the target task remain the same, but the source and the target domains differ in their underlying probability distribution (from [[2019 Ruder - Neural Transfer Learning for Natural Language Processing]]). Domain Adaptation was initially defined [[2009 Pan - A Survey on Transfer Learning]] as a setting in which no labeled data in the target domain are available, whicle a lot of labeled data in the source domain are available. [[2019 Ruder - Neural Transfer Learning for Natural Language Processing]] defined [[Supervised Domain Adaptation]], in which a small amount of target labels is available. In this paper we present two scenarios of Domain Adaptation: in the first scenario we have two datasets on the same task (i.e. Entity Typing), we assume to have a partial mapping between source and target types and we assume to have no target labeled data, lying on the original Domain Adaptation Definition[[2009 Pan - A Survey on Transfer Learning]]. In the second scenario we again ave two datasets on the same task (i.e. Entity Typing) and we assume to have a small amount of target labeled data, lying on the Supervised Domain Adaptation Definition [[2019 Ruder - Neural Transfer Learning for Natural Language Processing]].

Domain adaptation is deemed important for practical reasons and sustainability: the initial train (or pre-train) of the model can be costly in terms of required resources, data, electricity, and time; all these computational and natural resources cannot be expected to be always available to train a model for a new domain. In particular, [[2018 Ramponi - Neural Unsupervised Domain Adaptation in NLP, A Survey]] point to domain adaptation as a solution for labeled data lack
in a domain; [[2021 Hedderic - A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios]] discuss about general NLP approaches in Low-Resource Scenarios definining a categorization [[Low-resources scenarios categories]] for them:
\begin{itemize}
	\item scenarios in which task-specific labels availability is scarce
	\item scenarios in which unlabeled language or domain-specific text availability is scarce
	\item scenarios in which auxiliary data availability is scarce	
\end{itemize}
The work presented in this paper lies in two of those categories: we experimented a scenario in which there are no data from the target domain and only a manual partial-mapping is given between the source types and the target types and so there is a lack of task-specific labels and scarcity of auxiliary data, since the mappings are partial and not all the target typer are covered; the second scenario lies in the lack of task-specific labels category, since only a small subset of target training data are used in the domain adaptation phase.

Our first scenario, the domain adaptation with partial mappings between source and target types, shares some characteristichs with the Domain Divergence [[Domain Divergence]] research field: as reported by [[2020 Kashyap - Domain Divergences, A Survey and Empirical Analysis]] Domain Divergence is useful in \textit{Decisions in the Wild}, by helping practitioners in predicting the performance or drops in performance of a model in a new target domain. The performance drop is predicted starting from the divergence between domains measured using different methods (geometric, information-theoretic orhigher-order measures, see [[2020 Kashyap - Domain Divergences, A Survey and Empirical Analysis]] for an in-deep analysis).


We are not aware about previous work investigating domain adaptation in FET and UFET, while different approaches and analyses have been proposed for NER with shallow entity typing, which are reviewed in~\cite{rodriguez-etal-2018-transfer,nozza2021learningtoadapt}.
\citet{nozza2021learningtoadapt} and \citet{rodriguez-etal-2018-transfer} use predictions of types in the source ontology as features for a classifier, predicting types in the target ontology, or fine-tune encoders based on neural models on the target domain.
% In this paper we focus our attention to the cross domain problem in FET and UFET, investigating whether and under which conditions performance change on different data sets. In our study we assume that a partial mapping between the source and the target ontology can be established and used, and evaluate its effect in absence of additional training data for the new domain. 

Both \cite{nozza2021learningtoadapt} and \cite{rodriguez-etal-2018-transfer} require a training on the target domain, the approach presented here instead does not requires training and can be seen as an analysis on which setups (and types) require a train on the target domain. Clearly, since we assume the existence of a partial mapping, the unmapped types in the target domain need a training.

Finally, we mention some approaches that have studied transfer learning of language models fine-tuned to the NER task, but under different lenses. \citet{todorov2020transfer} apply their approach to a specific data set, i.e., historic news annotated considering relatively fine grained types (~21 types). Fine-tuning exploits additional training data for the target domain (and ontology). \citet{giorgiTransfer} investigate transfer learning in the biomedical domain. \citet{lee-etal-2020-chinese} train an encoder on English and then fine-tune it on a Chinese corpus.

#in_paper