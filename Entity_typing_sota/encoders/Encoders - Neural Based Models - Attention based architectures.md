Models with use attention mechanism in the input encoder

[[2017 Shimaoka - Neural Architectures for Fine-grained Entity Type Classification]]
[[2018 Choi - Ultra-Fine Entity Typing]]
[[2018 Xin - Improving Neural Fine-Grained Entity Typing with Knowledge Attention]]
[[2018 Xu - Neural Fine-Grained Entity Type Classification with Hierarchy-Aware Loss]]
[[2018 Zhang - Fine-grained Entity Typing through Increased Discourse Context and Adaptive Classification Thresholds]]
[[2018 Yuan - OTyper , A Neural Architecture for Open Named Entity Typing]]
[[2019 Chen - Improving Distantly-supervised Entity Typing with Compact Latent Space Clustering]]
[[2019 Wu - Modeling Noisy Hierarchical Types in Fine-Grained Entity Typing, A Content-Based Weighting Approach]]
[[2019 Lin - An Attentive Fine-Grained Entity Typing Model with Latent Type Representation]]
[[2019 Xiong - Imposing Label-Relational Inductive Bias for Extremely Fine-Grained Entity Typing]]
[[2019 Sahay - A Type-Specific Attention Model For Fine Grained Entity Type Classification]]
[[2021 Liu - Fine-grained Entity Typing via Label Reasoning]]

All models with [[Encoders - Neural Based Models - ELMo based architectures]]

All models with [[Encoders - Neural Based Models - BERT Based Architectures]]