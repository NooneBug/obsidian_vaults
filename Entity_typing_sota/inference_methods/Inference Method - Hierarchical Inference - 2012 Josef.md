[[2012 Yosef - HYENA, Hierarchical Type Classification for Entity Names]]: 

*Based on the feature set defined in the previous section, we build a set of type-specific classifiers using the SVM software liblinear (Fan et al., 2008; Chang and Lin, 2011). As our YAGO-based type system integrates WordNet and Wikipedia categories, we obtain ample training data from Wikipedia effortlessly, by following Wikipedia anchor texts to the corresponding YAGO entities. For each type, we consider Wikipedia mentions (and their context, cf. Section 2.2) of the type’s instances as positive training samples. For discriminative learning, we use all siblings in the type hierarchy as negative samples. As the subclasses of type t do not necessarily cover all entities, we add a subclass Others to each non-leaf type. Positive samples for Others are instances of type t that do not belong to any of its subclasses. Conversely, the classifiers for non-leaf nodes include all instances of their subtypes as positive samples (with full weight). HYENA performs type-specific classification in a top-down manner. A mention is assigned to all types for which the classifier signals acceptance. If rejected, classification is stopped at this level.*

*HYENA uses a global threshold θ for accepting to a class. Using a single parameter for all types is not fully satisfying, as different types may exhibit very different characteristics. So the optimal acceptance threshold may be highly type-dependent. To overcome this limitation, we devised a meta classifier that ranks the types for each test mention by decreasing confidence values and then predicts the “right” number of top-n labels to be assigned to a mention, similar to the methodology of (Tang et al., 2009). We use the confidence values of the type-specific classifier ensemble as meta-features, and train a multi-class logistic regression classifier to obtain a suitable value n of features. We combine the base classifiers and the meta classifier by first running the entire ensemble top-down along the type hierarchy, and then letting the meta model decide on how many of the highest-scoring types we accept for a mention.*

So like [[2010 Rahman - Inducing Fine-Grained Semantic Classes via Hierarchical and Collective Classification |2010 Rahman]] a tree of classifiers is defined and each classifier is used only if its father's classifier produced a high (???) output. Then a Meta classifier decides how many of the highest types predict.

#inference_method