The ultra-fine entity typing task proposed by [Choi et al. (2018)](obsidian://open?vault=Entity_typing_sota&file=paper%2F2018%20Choi%20-%20Ultra-Fine%20Entity%20Typing) uses a large, open type vocabulary to achieve better type coverage than the traditional fine-grained entity typing task [(Ling and Weld, 2012)](obsidian://open?vault=Entity_typing_sota&file=paper%2F2012%20Ling%20-%20Fine-Grained%20Entity%20Recognition) that uses manually designed entity type ontologies. There are only limited studies on this newly proposed task: A neural model introduced by [(Onoe and Durrett, 2019)](obsidian://open?vault=Entity_typing_sota&file=paper%2F2019%20Onoe%20-%20Learning%20to%20Denoise%20Distantly-Labeled%20Data%20for%20Entity%20Typing) filters samples that are too noisy to be used and relabels the remaining samples to get cleaner labels. A graph propagation layer is introduced by [(Xiong et al., 2019)](obsidian://open?vault=Entity_typing_sota&file=paper%2F2019%20Onoe%20-%20Learning%20to%20Denoise%20Distantly-Labeled%20Data%20for%20Entity%20Typing) to impose a label-relational bias on entity typing models, so as to implicitly capture type dependencies. [Onoe et al. (2021)](obsidian://open?vault=Entity_typing_sota&file=paper%2F2021%20Onoe%20-%20Modeling%20Fine-Grained%20Entity%20Types%20with%20Box%20Embeddings) use box embeddings to capture latent type hierarchies. There is also some work on the applications of ultra-fine entity typing: Onoe and Durrett (2020)

Apply ultra-fine entity typing to learn entity representations for two downstream tasks: coreference arc prediction and named entity disambiguation. The traditional fine-grained entity typing task ([Ling and Weld, 2012](obsidian://open?vault=Entity_typing_sota&file=paper%2F2012%20Ling%20-%20Fine-Grained%20Entity%20Recognition); [2012 Yosef - HYENA, Hierarchical Type Classification for Entity Names | Yosef et al., 2012](obsidian://open?vault=Entity_typing_sota&file=paper%2F2012%20Yosef%20-%20HYENA%2C%20Hierarchical%20Type%20Classification%20for%20Entity%20Names)) is closely related to ultra-fine entity typing. Automatic annotation ([Ling and Weld, 2012]; [Gillick et al., 2014](obsidian://open?vault=Entity_typing_sota&file=paper%2F2014%20Gillick%20-%20Context-Dependent%20Fine-Grained%20Entity%20Type%20Tagging); [Dai et al., 2020](obsidian://open?vault=Entity_typing_sota&file=paper%2F2020%20Dai%20-%20Exploiting%20Semantic%20Relations%20for%20Fine-grained%20Entity%20Typing)) is also commonly used in the studies of this task to produce large size training data. Many different approaches have been proposed to improve fine-grained entity typing performance. For example, denoising the automatically generated labels [(Ren et al., 2016)](obsidian://open?vault=Entity_typing_sota&file=paper%2F2016%20Ren%20-%20AFET%2C%20Automatic%20Fine-Grained%20Entity%20Typing%20by%20Hierarchical%20Partial-Label%20Embedding), taking advantage of the entity type hierarchies or type inter-dependencies [(Chen et al., 2020](obsidian://open?vault=Entity_typing_sota&file=paper%2F2020%20Chen%20-%20Hierarchical%20Entity%20Typing%20via%20Multi-level%20Learning%20to%20Rank); [Murty et al., 2018](obsidian://open?vault=Entity_typing_sota&file=paper%2F2018%20Murty%20-%20Hierarchical%20Losses%20and%20New%20Resources%20for%20Fine-grained%20Entity%20Typing%20and%20Linking); [Lin and Ji, 2019](obsidian://open?vault=Entity_typing_sota&file=paper%2F2019%20Lin%20-%20An%20Attentive%20Fine-Grained%20Entity%20Typing%20Model%20with%20Latent%20Type%20Representation)), exploiting external resources such as the information of entities provided in knowledge bases ([Jin et al., 2019](obsidian://open?vault=Entity_typing_sota&file=paper%2F2019%20Jin%20-%20Fine-grained%20entity%20typing%20via%20hierarchical%20multi%20graph%20convolutional%20networks); [Dai et al., 2019](obsidian://open?vault=Entity_typing_sota&file=paper%2F2019%20Dai%20-%20Improving%20Fine-grained%20Entity%20Typing%20with%20Entity%20Linking); [Xin et al., 2018](obsidian://open?vault=Entity_typing_sota&file=paper%2F2018%20Xin%20-%20Improving%20Neural%20Fine-Grained%20Entity%20Typing%20with%20Knowledge%20Attention)), etc.