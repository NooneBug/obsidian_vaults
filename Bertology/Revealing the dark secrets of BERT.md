[Paper link](https://arxiv.org/pdf/1908.08593.pdf)

A finding of this paper is that the different patterns observed in self-attention matrix are not related with tasks and so not linguistically informative (based on the patterns counted on the GLUE tasks)

A finding of this paper is that if attention which has to exploit *important relations* (for example the attention value from a pronouns to the verb in a sentence) are zeroed out, there is no performance drop